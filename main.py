import json
import os
import shutil
import time
from typing import Set
from uuid import uuid4

import pandas as pd
import streamlit as st
from streamlit_chat import message

from backend.core import run_llm_OPENAI
from db.DatabaseManager import DatabaseManager
from ingestion import chunk_make

# CSS for styling
st.markdown(
    """
    <style>
        .block-container {
            max-width: 80%;
        }
    </style>
""",
    unsafe_allow_html=True,
)


def create_sources_string(source_urls: Set[str]) -> str:
    """Generate a formatted string of sources."""
    sources_list = sorted(list(source_urls))
    return "\n".join([f"{i + 1}. {source}" for i, source in enumerate(sources_list)])


# Header
st.header("LangChainğŸ¦œğŸ”— Helper Bot")

# Session states initialization
for state, default_value in [
    ("user_prompt_history", []),
    ("chat_answers_history", []),
    ("chat_history", []),
    ("source_documents", []),
    ("show_k", True),
    ("show_answer", True),
]:
    st.session_state.setdefault(state, default_value)

if "db_manager" not in st.session_state:
    st.session_state["db_manager"] = DatabaseManager("chat_messages.db")
if "show_chat_history" not in st.session_state:
    st.session_state.show_chat_history = False
if "session_id" not in st.session_state:
    st.session_state["session_id"] = str(uuid4())

# Layout: Settings and Chat columns
conversation_column, settings_column, chat_column = st.columns([1, 2, 3])


def save_chat_history_to_db():
    session_id = st.session_state["session_id"]
    db_manager = st.session_state["db_manager"]

    if len(st.session_state["user_prompt_history"]) > 1:
        user_query = st.session_state["user_prompt_history"][-1]
        resp = st.session_state["chat_answers_history"][-1]
        source_docs_json = st.session_state["source_documents"][-1]
        # source_docs ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”í•©ë‹ˆë‹¤.
        source_docs = json.dumps(
            [
                {"page_content": doc.page_content, "metadata": doc.metadata}
                for doc in source_docs_json
            ],
            ensure_ascii=False,
        )
        fetch_k = search_kwargs.get("fetch_k", None)
        lambda_mult = search_kwargs.get("lambda_mult", None)
        k = search_kwargs.get("k", None)
        score_threshold = search_kwargs.get("score_threshold", None)

        db_manager.insert_message(
            user_query,
            k,
            fetch_k,
            lambda_mult,
            score_threshold,
            resp,
            source_docs,
            session_id,
        )
    else:
        for user_query, resp, source_docs_json in zip(
            st.session_state["user_prompt_history"],
            st.session_state["chat_answers_history"],
            st.session_state["source_documents"],
        ):
            # source_docs ë¦¬ìŠ¤íŠ¸ë¥¼ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”í•©ë‹ˆë‹¤.
            source_docs = json.dumps(
                [
                    {"page_content": doc.page_content, "metadata": doc.metadata}
                    for doc in source_docs_json
                ],
                ensure_ascii=False,
            )

            fetch_k = search_kwargs.get("fetch_k", None)
            lambda_mult = search_kwargs.get("lambda_mult", None)
            k = search_kwargs.get("k", None)
            score_threshold = search_kwargs.get("score_threshold", None)

            db_manager.insert_message(
                user_query,
                k,
                fetch_k,
                lambda_mult,
                score_threshold,
                resp,
                source_docs,
                session_id,
            )


def get_messages_by_session():
    db_manager = st.session_state["db_manager"]
    sessions = db_manager.fetch_sessions()

    # ì„¸ì…˜ ë°ì´í„°ë¥¼ ë³´ì—¬ì£¼ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“­ë‹ˆë‹¤.
    with st.container():
        # ì„¸ì…˜ ëª©ë¡ì—ì„œ ê° ì„¸ì…˜ì— ëŒ€í•´ ë²„íŠ¼ì„ ë§Œë“­ë‹ˆë‹¤.
        for user_query, session_id in sessions:
            # ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ í‚¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            session_state_key = f"clicked_{session_id}"

            # ì„¸ì…˜ ìƒíƒœê°€ ì €ì¥ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ Falseë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
            if session_state_key not in st.session_state:
                st.session_state[session_state_key] = False

            # ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œì˜ ë™ì‘ì„ ì •ì˜í•©ë‹ˆë‹¤.
            if st.button(
                f"ëŒ€í™” ì§ˆë¬¸: {user_query}\n\nsession: {session_id}", key=session_id
            ):
                # ë²„íŠ¼ ìƒíƒœë¥¼ í† ê¸€í•©ë‹ˆë‹¤.
                st.session_state[session_state_key] = not st.session_state[
                    session_state_key
                ]

            # ì„¸ì…˜ ìƒíƒœì— ë”°ë¼ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•˜ê±°ë‚˜ ìˆ¨ê¹ë‹ˆë‹¤.
            if st.session_state[session_state_key]:
                # í•´ë‹¹ ì„¸ì…˜ IDì˜ ë©”ì‹œì§€ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                messages = db_manager.fetch_messages_by_session(session_id)
                # ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ë˜ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“­ë‹ˆë‹¤.
                with st.container():
                    # ê°€ì ¸ì˜¨ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
                    for message in messages:
                        st.text_area(
                            f"Message ID: {message[0]}",
                            f"User: {message[1]}\nBot: {message[2]}",
                            height=100,
                        )
                        st.markdown("---")


# ì±„íŒ… ê¸°ë¡ì„ ìœ„í•œ ìë¦¬ í‘œì‹œì
chat_history_placeholder = st.empty()


def load_chat_history():
    db_manager = st.session_state["db_manager"]
    # DB ë§¤ë‹ˆì €ì—ì„œ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    all_messages = db_manager.fetch_all_messages()

    # ë°ì´í„°ë¥¼ íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    df_messages = pd.DataFrame(
        all_messages,
        columns=[
            "ID",
            "Session ID",
            "User Query",
            "Response",
            "Source Docs",
            "Timestamp",
        ],
    )

    # Streamlitì—ì„œ ë°ì´í„°í”„ë ˆì„ì„ í…Œì´ë¸”ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    st.dataframe(df_messages)


def clear_chat_history():
    chat_history_placeholder.empty()


# Settings Column
with settings_column:
    st.subheader("Settings")

    uploaded_file = st.file_uploader("Upload a DOCX file", type="docx")

    path = "langchain-docs/langchain.readthedocs.io/en/latest/fairy_tails/"

    if uploaded_file:
        st.write("Uploaded file:", uploaded_file.name)
        # íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        file_name_without_extension, _ = os.path.splitext(uploaded_file.name)
        # ì €ì¥í•  ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
        target_path = os.path.join(path, file_name_without_extension)

        # ì—…ë¡œë“œí•œ íŒŒì¼ì„ í•´ë‹¹ ê²½ë¡œì— ì €ì¥í•©ë‹ˆë‹¤.
        with open(target_path, "wb") as f:
            shutil.copyfileobj(uploaded_file, f)
            chunk_make(file_name_without_extension)

    # selected_filesë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ë§Œì•½ session_stateì— ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê¸°ì¡´ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    if "selected_files" not in st.session_state:
        st.session_state["selected_files"] = []

    if path:
        try:
            files = os.listdir(path)
            # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ê° íŒŒì¼ì— ëŒ€í•œ ì²´í¬ë°•ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            for file in files:
                file_name_without_extension, _ = os.path.splitext(file)
                # ì²´í¬ë°•ìŠ¤ ìœ„ì ¯ì„ ìƒì„±í•˜ê³ , í˜„ì¬ ìƒíƒœ(is_checked)ë¥¼ ì–»ìŠµë‹ˆë‹¤.
                is_checked = st.checkbox(
                    f"{file_name_without_extension}", key=file_name_without_extension
                )

                # ì²´í¬ë°•ìŠ¤ê°€ ì„ íƒë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ selected_files ë¦¬ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                if is_checked:
                    if (
                        file_name_without_extension
                        not in st.session_state["selected_files"]
                    ):
                        st.session_state["selected_files"].append(
                            file_name_without_extension
                        )
                else:
                    if (
                        file_name_without_extension
                        in st.session_state["selected_files"]
                    ):
                        st.session_state["selected_files"].remove(
                            file_name_without_extension
                        )
        except Exception as e:
            st.write(f"An error occurred: {e}")

    search_type = st.selectbox(
        "Select search type", ["mmr", "similarity", "similarity_score_threshold"]
    )
    chunk_size = st.selectbox("Select chunk size", [100, 200, 500, 1000, 1800])
    chunk_overlap = st.selectbox("Select chunk overlap", [0, 10])

    search_kwargs = {}
    k = st.text_input("k ë³€ìˆ˜ ì…ë ¥:", value="4")
    search_kwargs["k"] = int(k)

    if search_type == "similarity_score_threshold":
        score_threshold = st.text_input(
            "similarity_score_threshold ë³€ìˆ˜ ì…ë ¥:", value="0.8"
        )
        search_kwargs["score_threshold"] = float(score_threshold)

    elif search_type == "mmr":
        fetch_k = st.text_input("fetch_k ë³€ìˆ˜ ì…ë ¥:", value="20")
        lambda_mult = st.text_input("lambda_mult float 0~1 ë³€ìˆ˜ì…ë ¥:", value="0.5")
        search_kwargs.update(
            {"fetch_k": int(fetch_k), "lambda_mult": float(lambda_mult)}
        )
    elif search_type == "similarity":
        fetch_k = st.text_input("fetch_k ë³€ìˆ˜ ì…ë ¥:", value="20")
        search_kwargs.update({"fetch_k": int(fetch_k)})
    chain_type = st.selectbox("Select chainType", ["stuff", "map_reduce", "refine"])

    st.session_state["show_k"] = st.checkbox("K ê°’", value=st.session_state["show_k"])
    st.session_state["show_answer"] = st.checkbox(
        "ì‘ë‹µ", value=st.session_state["show_answer"]
    )

# Chat Column

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
db_manager = DatabaseManager("chat_messages.db")


with conversation_column:
    st.subheader("ëª¨ë“  ì„¸ì…˜ ëŒ€í™” ëª©ë¡")

    get_messages_by_session()

with chat_column:
    if st.button("ëŒ€í™” ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°/ìˆ¨ê¸°ê¸°"):
        st.session_state.show_chat_history = not st.session_state.show_chat_history
        if st.session_state.show_chat_history:
            load_chat_history()
        else:
            clear_chat_history()

    prompt = st.text_input("Prompt", value="", placeholder="Enter your message here...")
    answer = []
    if st.button("Submit"):
        if prompt:  # promptê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            with st.spinner("Generating response..."):
                responses = run_llm_OPENAI(
                    query=prompt,
                    search_type=search_type,
                    chat_history=st.session_state["chat_history"],
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    search_kwargs=search_kwargs,
                    chain_type=chain_type,
                    selected_files=st.session_state["selected_files"],
                )

                # ì‘ë‹µì„ ë°˜ë³µí•˜ë©° ê°ê° ì²˜ë¦¬í•©ë‹ˆë‹¤.
                for response in responses:
                    if "answer" in response:
                        # ì¤‘ë³µëœ promptë¥¼ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                        # if prompt not in st.session_state["user_prompt_history"]:
                        st.session_state["user_prompt_history"].append(prompt)
                        st.session_state["chat_answers_history"].append(
                            response["answer"]
                        )

                        # ì‘ë‹µì— ì†ŒìŠ¤ ë¬¸ì„œê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì²˜ë¦¬í•©ë‹ˆë‹¤.
                        if "source_documents" in response:
                            st.session_state["source_documents"].append(
                                response["source_documents"]
                            )
                        st.session_state["last_response"] = response["answer"]
                    save_chat_history_to_db()

    # Display messages
    if st.session_state.get("last_response"):
        unique_time = str(time.time()).replace(".", "")

        for idx, (user_query, resp, source_docs) in enumerate(
            zip(
                st.session_state["user_prompt_history"],
                st.session_state["chat_answers_history"],
                st.session_state["source_documents"],
            )
        ):
            message(user_query, is_user=True, key=f"user_msg_{idx}_{unique_time}")

            response_and_docs = resp  # ë´‡ì˜ ì‘ë‹µì„ ì‹œì‘ìœ¼ë¡œ í•©ë‹ˆë‹¤.

            # ë¬¸ì„œ K ê°’ì´ í‘œì‹œë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš° ì‘ë‹µì— ì¶”ê°€í•©ë‹ˆë‹¤.
            if st.session_state["show_k"]:
                for k in st.session_state["source_documents"][idx]:
                    page_content = k.page_content
                    source = k.metadata["source"]
                    file_name = source.split("/")[-1]
                    st.markdown(
                        f"""
                          <div style="background-color: rgba(255, 0, 0, 0.3);
                                      padding: 10px;
                                      border-radius: 5px;
                                      max-width: 80%;
                                      margin: 10px 0;">
                              ë°˜í™˜ëœ ë¬¸ì„œ K : {page_content}\n{file_name}
                          </div>
                          """,
                        unsafe_allow_html=True,
                    )

            # ì‘ë‹µì´ í‘œì‹œë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš° ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
            if st.session_state["show_answer"]:
                message(
                    response_and_docs, is_user=False, key=f"bot_msg_{idx}_{unique_time}"
                )

# ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¢…ë£Œë  ë•Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ë‹«ìŠµë‹ˆë‹¤.
db_manager.close()
